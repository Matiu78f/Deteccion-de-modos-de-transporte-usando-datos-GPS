{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from Libreria.cargar_configbd import cargar_configbd\n",
    "from Libreria.cargar_mes_a_procesar import cargar_mes_a_procesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a la base de datos PostgreSQL\n",
    "conn = cargar_configbd.conectar_base_datos('conf_bd.txt')\n",
    "# Crear un cursor para ejecutar consultas\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abr2024\n"
     ]
    }
   ],
   "source": [
    "mes, año = cargar_mes_a_procesar.leer_csv_en_lista('mes_a_procesar.csv')\n",
    "mes = 'abr'\n",
    "año = 2024\n",
    "print(f\"{mes}{año}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_anomala = f\"caracteristicas_viajes_{mes}{año}\"\n",
    "tabla_destino = f\"corregidos_viajes_{mes}{año}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corregir_outliers(df):\n",
    "\n",
    "    se_corrigio = False\n",
    "\n",
    "    def deteccion_outliers_isolation_forest(df, umbral_velocidad_maxima):\n",
    "\n",
    "        # Convertir a numpy array\n",
    "        X = np.array(df['speed']).reshape(-1, 1)\n",
    "\n",
    "        # Ajustar Isolation Forest\n",
    "        clf = IsolationForest(contamination=0.1)\n",
    "        clf.fit(X)\n",
    "\n",
    "        # Predecir outliers\n",
    "        y_pred = clf.predict(X)\n",
    "\n",
    "        # -1 son outliers, 1 son puntos normales\n",
    "        df['is_outlier'] = y_pred\n",
    "        \n",
    "        # Cambiar el valor de 'is_outlier' a 1 si 'speed' es menor que 40\n",
    "        df.loc[df['speed'] < umbral_velocidad_maxima, 'is_outlier'] = 1\n",
    "\n",
    "        se_corrigio = -1 in df['is_outlier'].values\n",
    "\n",
    "        if not se_corrigio:\n",
    "            return df, se_corrigio\n",
    "        \n",
    "        #Q3 sin outliers \n",
    "        Q3_sin_outliers = df[(df['is_outlier'] != -1) | (df['speed'] < umbral_velocidad_maxima)]['speed'].quantile(0.75)\n",
    "\n",
    "        # Filtrar outliers con velocidad mayor a 40 m/s\n",
    "        condition = (df['is_outlier'] == -1) | (df['speed'] > umbral_velocidad_maxima)\n",
    "\n",
    "        # Asignar el nuevo valor a los outliers que cumplen con la condición\n",
    "        df.loc[condition, 'speed'] = Q3_sin_outliers\n",
    "\n",
    "        return df, se_corrigio\n",
    "\n",
    "    umbral_velocidad_maxima = 35\n",
    "    df_corregido, se_corrigio = deteccion_outliers_isolation_forest(df.copy(), umbral_velocidad_maxima,)\n",
    "\n",
    "    if se_corrigio:\n",
    "        # Actualizar las aceleraciones con los datos de velocidades corregidos\n",
    "        df_corregido['aceleration'] = df_corregido['speed'].diff() / df_corregido['recorded_at'].diff().dt.total_seconds()\n",
    "        # La primera fila no tendrá aceleración porque no hay un punto anterior para comparar, la establecemos a 0\n",
    "        df_corregido.loc[0, \"aceleration\"] = df['aceleration'].iloc[0]\n",
    "\n",
    "    return df_corregido.drop(columns=['is_outlier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla para insertar datos corregidos\n",
    "consulta_sql =f'''DROP TABLE IF EXISTS corregidos_viajes_{mes}{año};\n",
    "                CREATE TABLE IF NOT EXISTS corregidos_viajes_{mes}{año}\n",
    "                    (\n",
    "                        tripid integer,\n",
    "                        uid character varying(50),\n",
    "                        latitude double precision,\n",
    "                        longitude double precision,\n",
    "                        distance double precision,\n",
    "                        speed double precision,\n",
    "                        aceleration double precision,\n",
    "                        bearing double precision,\n",
    "                        recorded_at timestamp without time zone\n",
    "                    );\n",
    "                '''\n",
    "\n",
    "cur.execute(consulta_sql)\n",
    "# Confirma los cambios en la base de datos\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(f\"SELECT DISTINCT tripid, uid FROM {tabla_anomala}\")\n",
    "# Obtener los resultados de la consulta\n",
    "rows = cur.fetchall()\n",
    "id_viajes = rows.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33044"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_viajes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_viajes: 33044\n",
      "Progreso: 33044\r"
     ]
    }
   ],
   "source": [
    "# ---- Corregir datos\n",
    "print(f\"n_viajes: {len(id_viajes)}\")\n",
    "prog_anterior = 1 # En uno aun no procesa nada\n",
    "id_viajes = id_viajes[prog_anterior - 1:]\n",
    "prog = prog_anterior - 1\n",
    "for id_viaje in id_viajes:\n",
    "    prog += 1\n",
    "    print(f\"Progreso: {prog}\", end=\"\\r\")\n",
    "\n",
    "    # Obtener los ids de todos los viajes\n",
    "    cur.execute(f\"SELECT * FROM {tabla_anomala} where tripid='{id_viaje[0]}' and uid='{id_viaje[1]}' order by recorded_at\")\n",
    "    #print(f\"SELECT * FROM {tabla_anomala} where tripid='{id_viaje[0]}' and uid='{id_viaje[1]}' order by recorded_at\")\n",
    "\n",
    "    rows = cur.fetchall()\n",
    "    puntos_viaje = rows.copy()\n",
    "\n",
    "    df = pd.DataFrame(puntos_viaje, columns=[desc[0] for desc in cur.description])\n",
    "    # Se eliminan nulos\n",
    "    df = df.dropna()\n",
    "    # Se eliminan posibles datos duplicados\n",
    "    df = df.drop_duplicates(subset=['recorded_at'], keep='first')\n",
    "    # Reiniciar los índices\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    # Se corrigen outliers fijandose en la  velocidad\n",
    "    df = corregir_outliers(df.copy())\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Construye la consulta SQL con parámetros\n",
    "        consulta_sql = \"\"\"\n",
    "        INSERT INTO {} VALUES (\n",
    "            %s, %s, %s, %s, %s, %s, %s, %s, %s\n",
    "        )\n",
    "        \"\"\".format(tabla_destino)\n",
    "\n",
    "        # Ejecuta la consulta SQL con los valores de la fila actual\n",
    "        cur.execute(consulta_sql, tuple(row))\n",
    " \n",
    "# Confirma los cambios en la base de datos\n",
    "conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
