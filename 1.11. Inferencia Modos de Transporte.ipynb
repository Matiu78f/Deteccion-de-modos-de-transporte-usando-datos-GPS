{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Libreria.cargar_configbd import cargar_configbd\n",
    "from Libreria.matriz_de_confusion import matriz_de_confusion\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a la base de datos PostgreSQL\n",
    "conn = cargar_configbd.conectar_base_datos('conf_bd.txt')\n",
    "# Crear un cursor para ejecutar consultas\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objetos cargados desde 'complete_model.joblib'\n"
     ]
    }
   ],
   "source": [
    "modelo_cargado = joblib.load('Modelos/complete_model_rf9992_sept_biciabr.joblib')\n",
    "\n",
    "# Acceder a los objetos individuales\n",
    "number_of_features = modelo_cargado['number_of_features']\n",
    "label_encoder = modelo_cargado['label_encoder']\n",
    "classifier = modelo_cargado['classifier']\n",
    "selected_features = modelo_cargado['selected_features']\n",
    "\n",
    "print(\"Objetos cargados desde 'complete_model.joblib'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificar dataset restante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediccion(modelo, df_new, label_encoder):\n",
    "    if isinstance(modelo, xgb.Booster):\n",
    "        # Convertir DataFrame a DMatrix si el modelo es XGBoost\n",
    "        dmatrix_new = xgb.DMatrix(data=df_new)\n",
    "        # Hacer predicciones con el nuevo conjunto de datos\n",
    "        y_pred_new_indices = modelo.predict(dmatrix_new)\n",
    "        # Invertir la codificaci√≥n de las etiquetas\n",
    "        y_pred_new = label_encoder.inverse_transform(y_pred_new_indices.astype(int))\n",
    "    else:\n",
    "        # Hacer predicciones directamente con el DataFrame si es otro tipo de modelo\n",
    "        y_pred_new = modelo.predict(df_new)\n",
    "\n",
    "    return y_pred_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meses = ['sept2023']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----SEPT2023----\n",
      "n_viajes: 35864\n",
      "Progreso: 35864\r"
     ]
    }
   ],
   "source": [
    "# Hacer las predicciones\n",
    "for mes in meses:\n",
    "\n",
    "    # Crear tablas para guardar etiquetas\n",
    "    for modo in ['CAMINATA', 'BICICLETA', 'BUS', 'AUTOMOVIL']:\n",
    "\n",
    "        # Crear tabla para insertar datos corregidos\n",
    "        consultas_sql = [f\"DROP TABLE IF EXISTS inferencia_segmentos_{modo}_{mes};\",\n",
    "            f\"\"\"CREATE TABLE IF NOT EXISTS inferencia_segmentos_{modo}_{mes}\n",
    "                (\n",
    "                    tripid integer,\n",
    "                    segid integer,\n",
    "                    uid character varying(50)\n",
    "                );\n",
    "            \"\"\"]\n",
    "\n",
    "        for consulta_sql in consultas_sql:\n",
    "            cur.execute(consulta_sql)\n",
    "        # Confirma los cambios en la base de datos\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "    cur.execute(f'''SELECT DISTINCT tripid, segid, uid \n",
    "                    FROM segmentos_viajes_{mes};\n",
    "                ''')\n",
    "    # Obtener los segmentos del mes\n",
    "    rows = cur.fetchall()\n",
    "    id_segmentos = rows.copy()\n",
    "\n",
    "    print(f'----{mes.upper()}----')\n",
    "    print(f\"n_viajes: {len(id_segmentos)}\")\n",
    "    prog_anterior = 1 # En uno aun no precesa nada\n",
    "    id_segmentos = id_segmentos[prog_anterior - 1:]\n",
    "    prog = prog_anterior - 1\n",
    "    for id_segmento in id_segmentos:\n",
    "        prog += 1\n",
    "        print(f\"Progreso: {prog}\", end=\"\\r\")   \n",
    "\n",
    "        # Obtener los puntos del viaje\n",
    "        cur.execute(f'''SELECT * FROM estadisticos_segmentos_{mes} \n",
    "                    where tripid = '{id_segmento[0]}' and segid = '{id_segmento[1]}' and uid = '{id_segmento[2]}'; ''')\n",
    "        #print(f\"SELECT * FROM estadisticos_viajes_sept2023 where tripid = '{id_segmento[0]}' and segid = '{id_segmento[1]}' and uid = '{id_segmento[2]}';\")\n",
    "        df_new = pd.DataFrame(cur.fetchall().copy(), columns=[desc[0] for desc in cur.description])\n",
    "\n",
    "        pred = prediccion(classifier, df_new[selected_features[:number_of_features]], label_encoder)\n",
    "        #pred = prediccion(classifier, normalize_data(df_new[selected_features[:number_of_features]]), label_encoder)\n",
    "        #print(pred[0])\n",
    "\n",
    "        consulta_sql = \"\"\"\n",
    "        INSERT INTO {} VALUES (\n",
    "            %s, %s, %s\n",
    "        )\n",
    "        \"\"\".format(f'inferencia_segmentos_{pred[0]}_{mes}')\n",
    "\n",
    "        # Ejecuta la consulta SQL con los valores de la fila actual\n",
    "        cur.execute(consulta_sql, id_segmento)\n",
    "        conn.commit() # Hace commit cuando inserta todo el viaje'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEPT2023\n",
      "etiqueta\n",
      "AUTOMOVIL     7887\n",
      "BICICLETA     2549\n",
      "BUS          10097\n",
      "CAMINATA     15331\n",
      "dtype: int64\n",
      "\n",
      "TOTAL\n",
      "etiqueta\n",
      "AUTOMOVIL     7887\n",
      "BICICLETA     2549\n",
      "BUS          10097\n",
      "CAMINATA     15331\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "infered_data_mes = []\n",
    "for mes in meses:\n",
    "    print(mes.upper())\n",
    "\n",
    "    modos = ['CAMINATA', 'BICICLETA', 'BUS', 'AUTOMOVIL']\n",
    "\n",
    "    # inferencia_segmentos tienen todos los segmentos clasificados por el modelo supervisado final\n",
    "    dfs = []\n",
    "\n",
    "    for modo in modos: \n",
    "        \n",
    "        consulta_sql = f'''\n",
    "                        SELECT o.*\n",
    "                            FROM public_new.estadisticos_segmentos_{mes} o\n",
    "                            JOIN public_new.inferencia_segmentos_{modo}_{mes} i \n",
    "                            ON o.tripid = i.tripid\n",
    "                            AND o.segid = i.segid\n",
    "                            AND o.uid = i.uid;\n",
    "                        '''\n",
    "        \n",
    "        cur.execute(consulta_sql)\n",
    "        df = pd.DataFrame(cur.fetchall().copy(), columns=[desc[0] for desc in cur.description])\n",
    "        df['etiqueta'] = modo\n",
    "\n",
    "        dfs.append(df)\n",
    "\n",
    "    infered_data = pd.concat(dfs, ignore_index=True)\n",
    "    num_elementos_por_grupo = infered_data.groupby('etiqueta').size()\n",
    "    print(num_elementos_por_grupo)\n",
    "\n",
    "    infered_data_mes.append(infered_data)\n",
    "    print(\"\")\n",
    "\n",
    "print(\"TOTAL\")\n",
    "df_infered_data_mes = pd.concat(infered_data_mes, ignore_index=True)\n",
    "num_elementos_por_grupo = df_infered_data_mes.groupby('etiqueta').size()\n",
    "print(num_elementos_por_grupo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for mes in ['sept2023']:\n",
    "  # -----Agregar columnas para caracteristicas nuevas\n",
    "  consulta_sql = f'''DROP TABLE IF EXISTS datos_uda_inferencia_{mes};\n",
    "                    CREATE TABLE datos_uda_inferencia_{mes} (\n",
    "                        tripid INTEGER,\n",
    "                        segid INTEGER,\n",
    "                        uid VARCHAR(255),\n",
    "                        p25_speed FLOAT, \n",
    "                        p75_speed FLOAT,\n",
    "                        max_speed FLOAT,\n",
    "                        min_speed FLOAT,\n",
    "                        mean_speed FLOAT,\n",
    "                        median_speed FLOAT,\n",
    "                        var_speed FLOAT,\n",
    "                        p25_aceleration FLOAT, \n",
    "                        p75_aceleration FLOAT,\n",
    "                        max_aceleration FLOAT,\n",
    "                        min_aceleration FLOAT,\n",
    "                        mean_aceleration FLOAT,\n",
    "                        median_aceleration FLOAT,\n",
    "                        var_aceleration FLOAT,\n",
    "                        p25_bearing FLOAT, \n",
    "                        p75_bearing FLOAT,\n",
    "                        max_bearing FLOAT,\n",
    "                        min_bearing FLOAT,\n",
    "                        mean_bearing FLOAT,\n",
    "                        median_bearing FLOAT,\n",
    "                        var_bearing FLOAT,\n",
    "                        p25_time_stop FLOAT, \n",
    "                        p75_time_stop FLOAT,\n",
    "                        max_time_stop FLOAT,\n",
    "                        min_time_stop FLOAT,\n",
    "                        mean_time_stop FLOAT,\n",
    "                        median_time_stop FLOAT,\n",
    "                        var_time_stop FLOAT,\n",
    "                        stops INTEGER,\n",
    "                        etiqueta VARCHAR(50)\n",
    "                    );\n",
    "                  '''\n",
    "  cur.execute(consulta_sql)\n",
    "  cur.execute(f\"commit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----SEPT2023----\n",
      "n_viajes_inferidos: 38943\n",
      "Progreso: 38943\r"
     ]
    }
   ],
   "source": [
    "for mes, infered_data in zip(['sept2023'], infered_data_mes):\n",
    "\n",
    "    print(f'----{mes.upper()}----')\n",
    "    print(f\"n_viajes_inferidos: {len(infered_data)}\")\n",
    "    prog = 0\n",
    "    for idx, row in infered_data.iterrows():\n",
    "        prog += 1\n",
    "        print(f\"Progreso: {prog}\", end=\"\\r\")  \n",
    "        \n",
    "        consulta_sql = \"\"\"\n",
    "        INSERT INTO {} VALUES (\n",
    "            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "            %s, %s, %s\n",
    "        )\n",
    "        \"\"\".format(f'datos_uda_inferencia_{mes}')\n",
    "\n",
    "        cur.execute(consulta_sql, tuple(row))\n",
    "        conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
