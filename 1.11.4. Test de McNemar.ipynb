{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"0EKkhulYjXzu"},"outputs":[],"source":["import numpy as np\n","import pickle\n","import itertools\n","from statsmodels.stats.contingency_tables import mcnemar\n","from sklearn.metrics import balanced_accuracy_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xBcqXMlBjXzv"},"outputs":[],"source":["def contingency_table(y_true, y_pred1, y_pred2):\n","    table = np.zeros((2, 2))\n","    for yt, yp1, yp2 in zip(y_true, y_pred1, y_pred2):\n","        if yp1 == yt and yp2 == yt:\n","            table[0, 0] += 1\n","        elif yp1 == yt and yp2 != yt:\n","            table[0, 1] += 1\n","        elif yp1 != yt and yp2 == yt:\n","            table[1, 0] += 1\n","        else:\n","            table[1, 1] += 1\n","    return table"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H2OiCpdjjXzv","outputId":"d5897b13-1943-486f-c980-666a5e6e7eb7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Balanced acurracies \n","{'DT': 0.975, 'SVM': 0.8477011494252874, 'XGB': 0.9833333333333334, 'RF': 0.975}\n","\n"," McNemar\n","Comparación entre DT y SVM:\n","Estadístico de McNemar: 9.333333333333334\n","Valor p: 0.0022502265680857947\n","\n","Comparación entre DT y XGB:\n","Estadístico de McNemar: 0.0\n","Valor p: 1.0\n","\n","Comparación entre DT y RF:\n","Estadístico de McNemar: inf\n","Valor p: 0.0\n","\n","Comparación entre SVM y XGB:\n","Estadístico de McNemar: 12.5\n","Valor p: 0.00040695201744495946\n","\n","Comparación entre SVM y RF:\n","Estadístico de McNemar: 9.333333333333334\n","Valor p: 0.0022502265680857947\n","\n","Comparación entre XGB y RF:\n","Estadístico de McNemar: 0.0\n","Valor p: 1.0\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Mateo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\stats\\contingency_tables.py:1348: RuntimeWarning: divide by zero encountered in scalar divide\n","  statistic = (np.abs(n1 - n2) - corr)**2 / (1. * (n1 + n2))\n"]}],"source":["file_path = 'predicciones_modelos.pkl'\n","with open(file_path, 'rb') as file:\n","        models_predictions = pickle.load(file)\n","        #print(f\"Datos cargados desde {file_path}\")\n","y_test = models_predictions['y_test']\n","\n","# Calcular balanced accuracy para cada modelo\n","balanced_accuracies = {}\n","for model_name, y_pred in models_predictions.items():\n","    if model_name != 'y_test':\n","        balanced_accuracies[model_name] = balanced_accuracy_score(y_test, y_pred)\n","\n","print('Balanced acurracies \\n' + str(balanced_accuracies) + '\\n\\n McNemar')\n","\n","results_mcnemar = {}\n","# Comparación par a par de los modelos utilizando el test de McNemar\n","for model1_name, model2_name in itertools.combinations(models_predictions.keys(), 2):\n","    if model1_name == 'y_test' or model2_name == 'y_test':\n","        continue\n","\n","    pred1 = models_predictions[model1_name]\n","    pred2 = models_predictions[model2_name]\n","\n","    # Calcula la tabla de contingencia\n","    contingency_tab = contingency_table(y_test, pred1, pred2)\n","\n","    # Realiza el test de McNemar\n","    mcnemar_result = mcnemar(contingency_tab, exact=False, correction=True)\n","\n","    # Guarda los resultados\n","    results_mcnemar[(model1_name, model2_name)] = mcnemar_result\n","\n","# Imprime los resultados\n","for (model1_name, model2_name), result in results_mcnemar.items():\n","    print(f\"Comparación entre {model1_name} y {model2_name}:\")\n","    print(\"Estadístico de McNemar:\", result.statistic)\n","    print(\"Valor p:\", result.pvalue)\n","    print()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}